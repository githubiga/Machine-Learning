{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction de caractéristiques à partir du texte\n",
    "<a href=\"madani.a@ucd.ac.ma\">madani.a@ucd.ac.ma</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "<p>\n",
    "Cet article sert d'une simple introduction à l'extraction des caractéristiques à partir de texte en utilisant Sci-Kit Learn de Python. Ces caractéristiques seront utilisées par la suite dans un modèle d'apprentissage automatique.\n",
    "</p>\n",
    "<p>\n",
    "La plupart des algorithmes de machine learning ne peuvent pas traiter directement un texte, nous allons donc créer une matrice de valeurs numériques pour représenter notre texte.\n",
    "</p>\n",
    "<p>\n",
    "Avant d’entrer dans le vif du sujet, il y a quelques termes que nous devons définir dès le départ.\n",
    "</p>\n",
    "<ul>\n",
    "<li><strong>document</strong> : fait référence à une seule information textuelle. Cela pourrait être un message textuel, un tweet, un e-mail, un livre, les paroles d'une chanson. \n",
    "<li><strong>corpus</strong> : une collection de documents. Cela équivalent à un ensemble de données de lignes / observations.\n",
    "<li><strong>jeton/token</strong> : il s'agit d'un mot, d'une phrase ou de symboles. \n",
    "</ul>\n",
    "<p>\n",
    "Commençons par définir un corpus de quelques exemples de messages texte.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey hey hey lets go get lunch today',\n",
       " 'Did you go home?',\n",
       " 'Go Hey!!! I need a favor']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0=\"Hey hey hey lets go get lunch today\"\n",
    "d1=\"Did you go home?\"\n",
    "d2=\"Go Hey!!! I need a favor\"\n",
    "corpus = [d0, d1, d2]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "<p>\n",
    "Tout d'abord, nous allons utiliser <strong>CountVectorizer()</strong> de sci-kit learn pour créer une matrice de nombres pour représenter nos messages. CountVectorizer() produit ce qu'on appelle un <strong>sac de mots (Bag Of Words)</strong>. Chaque message est divisé en tokens et le nombre de fois qu'un token apparaît dans un message est compté.\n",
    "</p>\n",
    "<p>\n",
    "Pour commencer, nous allons importer <strong>CountVectorizer</strong> de sklearn et l'instancier en tant qu'objet, comme nous le ferons avec un classificateur de sklearn. En fait, l'utilisation est très similaire. Au lieu d'utiliser les méthodes <strong>fit()</strong> et <strong>predict()</strong>, nous utiliserons la méthode <strong>fit()</strong> puis la méthode <strong>transform()</strong>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la méthode fit(), CountVectorizer () va \"apprendre\" ce que les tokens qui sont utilisés dans nos messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la méthode <strong>get_feature_names()</strong>, nous pouvons voir quelles caractéristiques (features) ont été créées à partir de nos messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['did', 'favor', 'get', 'go', 'hey', 'home', 'lets', 'lunch',\n",
       "       'need', 'today', 'you'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La propriété <strong>vocabulary_</strong> permet d'afficher le vocabulaire appris à partir de notre corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hey': 4,\n",
       " 'lets': 6,\n",
       " 'go': 3,\n",
       " 'get': 2,\n",
       " 'lunch': 7,\n",
       " 'today': 9,\n",
       " 'did': 0,\n",
       " 'you': 10,\n",
       " 'home': 5,\n",
       " 'need': 8,\n",
       " 'favor': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Il y a quelques points à noter ici.\n",
    "</p>\n",
    "<ul>\n",
    "<li>Tout est en minuscules\n",
    "<li>Les mots de moins de deux lettres n'ont pas été inclus\n",
    "<li>La ponctuation a été supprimée\n",
    "<li>Il n'y a pas de doublons\n",
    "</ul>\n",
    "<p>\n",
    "En changeant les arguments par défaut lorsque CountVectorizer est instancié, vous pouvez changer ce qui a été mentionné dans les deux premiers points si vous le souhaitez.\n",
    "</p>\n",
    "<p>\n",
    "Ensuite, transformons notre objet CountVectorizer. Cela créera une matrice peuplée de nombres de tokens par message. Cette matrice est souvent appelé une term document matrix. \n",
    "</p>\n",
    "<p>\n",
    "Dans notre cas, nous allons nommer la sortie représentant cette matrice dtm (document term matrix). Nous pouvons aussi afficher des informations sur la matrice ainsi que la matrice elle-même.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 3 0 1 1 0 1 0]\n",
      " [1 0 0 1 0 1 0 0 0 0 1]\n",
      " [0 1 0 1 1 0 0 0 1 0 0]]\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t3\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 8)\t1\n"
     ]
    }
   ],
   "source": [
    " dtm = vect.transform(corpus)\n",
    "print(dtm.toarray())\n",
    "print(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Chacun de nos messages contient seulement 3 à 6 tokens uniques et nous avons 11 caractéristiques différentes créées à partir de tous les messages. Cela signifie que chaque ligne sera principalement remplie de zéros. \n",
    "</p>\n",
    "<p>\n",
    "Afin de gagner de l'espace / puissance de calcul, une matrice clairsemée (sparse matrix) est créée. Cela signifie que seul l'emplacement et la valeur des valeurs non nulles sont sauvegardés. Nous pouvons aussi la convertir sous forme d’un dataframe pandas pour une meilleure visualisation\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   did  favor  get  go  hey  home  lets  lunch  need  today  you\n",
       "0    0      0    1   1    3     0     1      1     0      1    0\n",
       "1    1      0    0   1    0     1     0      0     0      0    1\n",
       "2    0      1    0   1    1     0     0      0     1      0    0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Par exemple, la troisième entrée dans notre matrice sparse est:\n",
    "</p>\n",
    "<strong><center>(0,4)    3</center></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Ce qui correspond au 1er message et à la 5ème caractéristique, 'hey'. L'entrée est 3 car notre 1er message avait trois fois le mot 'hey'.\n",
    "</p>\n",
    "<p>\n",
    "Nous sommes maintenant prêts à fournir une matrice de termes par documents à notre classificateur de Machine Learning.\n",
    "</p>\n",
    "\n",
    "### Remarque\n",
    "Il y a une chose qu’il faut bien souligner. Supposons que nous avons reçu un autre message peu après avoir créé la matrice de terme par documents et que nous souhaitions l'ajouter. Nous allons le transformer en une matrice de terme par documents à l'aide de notre objet CountVectorizer () que nous avons adapté précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   did  favor  get  go  hey  home  lets  lunch  need  today  you\n",
       "0    0      0    1   1    1     0     1      0     0      0    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4 = ['Hey lets go get a drink tonight']\n",
    "new_dtm = vect.transform(d4)\n",
    "pd.DataFrame(new_dtm.toarray(), columns=vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, même s'il contient 6 tokens uniques (à l’exception de 'a'), il n'y a que 4 entrées dans notre dtm. Les tokens «drink» et «tonight» ne sont pas représentés. C'est parce que nos messages originaux utilisés pour CountVectorizer () n'avaient pas ces tokens. Nous pouvons ajouter notre nouveau message à notre collection originale, puis refit() et transform() pour nous assurer de ne pas perdre cette information. Au lieu de ça, nous allons utiliser la méthode fit_transform() combinant fit() et transform()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hey hey hey lets go get lunch today', 'Did you go home?', 'Go Hey!!! I need a favor', 'Hey lets go get a drink tonight']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>drink</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   did  drink  favor  get  go  hey  home  lets  lunch  need  today  tonight  \\\n",
       "0    0      0      0    1   1    3     0     1      1     0      1        0   \n",
       "1    1      0      0    0   1    0     1     0      0     0      0        0   \n",
       "2    0      0      1    0   1    1     0     0      0     1      0        0   \n",
       "3    0      1      0    1   1    1     0     1      0     0      0        1   \n",
       "\n",
       "   you  \n",
       "0    0  \n",
       "1    1  \n",
       "2    0  \n",
       "3    0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.append(d4[0])\n",
    "print(corpus)\n",
    "\n",
    "dtm = vect.fit_transform(corpus)\n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer\n",
    "<p>\n",
    "Une alternative à CountVectorizer() est la méthode TfidfVectorizer(). Cette méthode créée également une matrice de terme par documents à partir de nos messages. Cependant, au lieu de remplir le DTM avec des nombres de fois qu’un token apparaît dans un message (document), il calcule la valeur de la fréquence TF-IDF. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rappel\n",
    "<p>Pour claculer la valeur de IF-IDF, on utilise la formule suivante :</p>\n",
    "<img src=\"images/tfidf.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>drink</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294188</td>\n",
       "      <td>0.194720</td>\n",
       "      <td>0.714511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294188</td>\n",
       "      <td>0.37314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.37314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318782</td>\n",
       "      <td>0.389916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.610878</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398060</td>\n",
       "      <td>0.263472</td>\n",
       "      <td>0.322264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398060</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.504889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        did     drink     favor       get        go       hey      home  \\\n",
       "0  0.000000  0.000000  0.000000  0.294188  0.194720  0.714511  0.000000   \n",
       "1  0.552805  0.000000  0.000000  0.000000  0.288477  0.000000  0.552805   \n",
       "2  0.000000  0.000000  0.610878  0.000000  0.318782  0.389916  0.000000   \n",
       "3  0.000000  0.504889  0.000000  0.398060  0.263472  0.322264  0.000000   \n",
       "\n",
       "       lets    lunch      need    today   tonight       you  \n",
       "0  0.294188  0.37314  0.000000  0.37314  0.000000  0.000000  \n",
       "1  0.000000  0.00000  0.000000  0.00000  0.000000  0.552805  \n",
       "2  0.000000  0.00000  0.610878  0.00000  0.000000  0.000000  \n",
       "3  0.398060  0.00000  0.000000  0.00000  0.504889  0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "dtm = vect.fit_transform(corpus)\n",
    "    \n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names_out()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de la similarité Cosinus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>La similarité cosinus est fréquemment utilisée en tant que mesure de ressemblance entre deux documents. Il pourra s'agir de comparer les textes issus d'un corpus dans une optique de classification (regrouper tous les documents relatifs à une thématique particulière), ou de recherche d'information.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05617211, 1.        , 0.09196106, 0.0760055 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(dtm[1:2], dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de synthèse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>bright</th>\n",
       "      <th>can</th>\n",
       "      <th>he</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>see</th>\n",
       "      <th>shining</th>\n",
       "      <th>sky</th>\n",
       "      <th>sun</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>thinks</th>\n",
       "      <th>we</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.379788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265205</td>\n",
       "      <td>0.470737</td>\n",
       "      <td>0.224309</td>\n",
       "      <td>0.470737</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.67491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.585047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.350906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523965</td>\n",
       "      <td>0.295193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422732</td>\n",
       "      <td>0.295193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.267302</td>\n",
       "      <td>0.399131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399131</td>\n",
       "      <td>0.322016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      blue    bright       can        he        in        is       see  \\\n",
       "0  0.00000  0.000000  0.000000  0.470737  0.000000  0.265205  0.000000   \n",
       "1  0.67491  0.000000  0.000000  0.000000  0.000000  0.380232  0.000000   \n",
       "2  0.00000  0.585047  0.000000  0.000000  0.000000  0.492160  0.000000   \n",
       "3  0.00000  0.350906  0.000000  0.000000  0.523965  0.295193  0.000000   \n",
       "4  0.00000  0.267302  0.399131  0.000000  0.000000  0.000000  0.399131   \n",
       "\n",
       "    shining       sky       sun      that       the    thinks        we  \n",
       "0  0.379788  0.000000  0.265205  0.470737  0.224309  0.470737  0.000000  \n",
       "1  0.000000  0.544513  0.000000  0.000000  0.321598  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.492160  0.000000  0.416266  0.000000  0.000000  \n",
       "3  0.000000  0.422732  0.295193  0.000000  0.499345  0.000000  0.000000  \n",
       "4  0.322016  0.000000  0.449726  0.000000  0.380376  0.000000  0.399131  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd \n",
    "\n",
    "d0=\"he thinks that the sun is shining\"\n",
    "d1=\"The sky is blue\"\n",
    "d2=\"The sun is bright\"\n",
    "d3=\"The sun in the sky is bright\"\n",
    "d4=\"We can see the shining sun, the bright sun\"\n",
    "\n",
    "corpus =[d0, d1, d2, d3, d4]\n",
    "\n",
    "#vect = CountVectorizer() # ==> TF\n",
    "vect=TfidfVectorizer() # ==> TF-IDF\n",
    "vect.fit(corpus)\n",
    "dtm = vect.transform(corpus)\n",
    "#print(dtm)\n",
    "#print(dtm.toarray())\n",
    "df = pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names_out())\n",
    "df\n",
    "#cosine_similarity(dtm[0:1], dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application\n",
    "<p>\n",
    "Etant donné un corpus constitué de plusieurs documents textuels, écrire un programme qui permet d'afficher les documents similaire à une requête donnée.\n",
    "</p>\n",
    "<p><strong>Proposition</strong></p>\n",
    "<ul>\n",
    "<li>Lire les documents et les stocker dans une liste : corpus\n",
    "<li>Néttoyer le corpus : éliminer les stopwords, les ponctuations, symboles, ...\n",
    "<li>Réduire les tokens en leurs racines\n",
    "<li>Dégager le BOW\n",
    "<li>Utiliser TF-IDF\n",
    "<li>Uiliser la méthode de similarité Cosinus\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.23036263, 0.28428975, 0.2489833 , 0.10646105]]),\n",
       " array([[0.10646105, 0.23036263, 0.2489833 , 0.28428975]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "d1=\"The sky is blue\"\n",
    "d2=\"The sun is bright\"\n",
    "d3=\"The sun in the sky is bright\"\n",
    "d4=\"We can see the shining sun, the bright sun\"\n",
    "files=[d1,d2,d3,d4]\n",
    "\"\"\"\n",
    "fichiers=['file1.txt','file2.txt','file3.txt','file4.txt']\n",
    "files=[]\n",
    "for file in fichiers:\n",
    "    f=open(file,\"r\")\n",
    "    l=f.read()\n",
    "    f.close()\n",
    "    files.append(l)\n",
    "\n",
    "\n",
    "print(files)\n",
    "\"\"\"\n",
    "req = 'the weather is fine'#input(\"requette :\")\n",
    "files.append(req)\n",
    "vect=TfidfVectorizer()\n",
    "vect.fit(files)\n",
    "dtm = vect.transform(files)\n",
    "#pour ne pas calculer la similarité de la requête avec elle-même\n",
    "similarities = cosine_similarity(dtm[4], dtm[0:4]) \n",
    "similarities, np.sort(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23 , 0.284, 0.249, 0.106]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(similarities,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The sky is blue': 0.2303626262240333,\n",
       " 'The sun is bright': 0.28428974981323174,\n",
       " 'The sun in the sky is bright': 0.24898329593578014,\n",
       " 'We can see the shining sun, the bright sun': 0.10646104858688445}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={}\n",
    "for i in range(len(files)-1):\n",
    "    d[files[i]] = similarities[0,i]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'files/file1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ea794b778d6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfichiers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'files/file1.txt'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fichiers=['files/file1.txt','files/file2.txt',\n",
    "          'files/file3.txt','files/file4.txt']\n",
    "corpus=[]\n",
    "for file in fichiers:\n",
    "    f=open(file,\"r\")\n",
    "    data=f.read()\n",
    "    f.close()\n",
    "    corpus.append(data)\n",
    "\n",
    "req = 'the weather is fine'#input(\"requette :\")\n",
    "corpus.append(req)\n",
    "print(corpus)\n",
    "vect=TfidfVectorizer()\n",
    "vect.fit(corpus)\n",
    "dtm = vect.transform(corpus)\n",
    "#pour ne pas calculer la similarité de la requête avec elle-même\n",
    "similarities = cosine_similarity(dtm[4], dtm[0:4]) \n",
    "similarities, np.sort(similarities[0])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fichiers = []\n",
    "for file in os.listdir(\"files/\"):\n",
    "    fichiers.append('files/'+file)\n",
    "\n",
    "\n",
    "corpus=[]\n",
    "for file in fichiers:\n",
    "    f=open(file,\"r\")\n",
    "    data=f.read()\n",
    "    f.close()\n",
    "    corpus.append(data)\n",
    "\n",
    "req = 'the weather is fine'#input(\"requette :\")\n",
    "corpus.append(req)\n",
    "print(corpus)\n",
    "vect=TfidfVectorizer()\n",
    "vect.fit(corpus)\n",
    "dtm = vect.transform(corpus)\n",
    "#pour ne pas calculer la similarité de la requête avec elle-même\n",
    "similarities = cosine_similarity(dtm[4], dtm[0:4]) \n",
    "similarities, np.sort(similarities[0])[::-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
