{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 4 : Validation de modèles\n",
    "\n",
    "Email : <a href='mailto:madani.a@ucd.ac.ma'>madani.a@ucd.ac.ma</a>\n",
    "<img src='images/robot.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "<p>\n",
    "Il est toujours nécessaire de valider la stabilité de votre modèle d'apprentissage automatique. Cela veut dire qu'il ne suffit pas d'adapter le modèle à vos données d'entraînement et espérer qu'il fonctionnerait avec précision pour les données réelles qu'il n'a jamais vues auparavant. \n",
    "</p>\n",
    "<p>\n",
    "Dans ce chapitre nous allons aborder le principe de validation de modèles dans le contexte de machine learning. Après une petite description des méthodes de validation les plus populaires, nous allons présenter des exemples d'implémentation en utilisant le langage Python.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validation\n",
    "\n",
    "<p>\n",
    "Le processus consistant à déterminer si les résultats numériques quantifiant les relations entre les variables sont acceptables en tant que descriptions des données est appelé validation.\n",
    "\n",
    "Dans ce processus, une estimation numérique de la différence entre les réponses prédites et les réponses originales est effectuée. Cette estimation est appelée erreur d'apprentissage. Elle nous permet d'avoir une idée sur la qualité de notre modèle. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Plusieurs modèles de validation utilisés dans le contexte de machine learning sont proposés, mais nous n'allons aborder que quelques unes. Pour plus d'informations sur d'autres modèles, consultez <a href=\"http://scikit-learn.org/stable/modules/cross_validation.html\">ce lien </a>\n",
    "</p>\n",
    "<p>\n",
    "Dans la suite de ce chapitre, nous allons tester quelques approches de validation appliqués à l'algorithme KNN en utilisant le dataset Iris. On peut utiliser n'importe quel autre algorithme (SVM, Regression lineaire, ...).\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons commencer par importer le dataset Iris que nous allons utiliser dans les exemples de ce chapitre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "# Importer load_iris() permettant de charger le dataset Iris\n",
    "from sklearn.datasets import load_iris\n",
    "# Charger le dataset Iris\n",
    "iris = load_iris()\n",
    "# X : données\n",
    "X = iris.data\n",
    "# y : classes\n",
    "y = iris.target\n",
    "#Vérifier la structure de X et y\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exemples de modèles de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Entraîner et tester sur le Dataset entier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette procédure, appelée aussi approche <strong>naîve</strong>, consiste à :\n",
    "<ul>\n",
    "<li>Entraîner le modèle sur le dataset en entier\n",
    "<li>Tester le modèle sur le même dataset, et évaluer à quel point nous avons bien comparé les valeurs de classess prédites avec les vraies valeurs de réponse.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par choisir un modèle et ses hyperparamètres. Dans notre exemple, nous allons utiliser le classificateur k-neighbors avec n_neighbors = 5 (valeur par défaut)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# clf pour classifieur. Un classifieur est un modèle, tels que KNN, SVC, ...\n",
    "clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous entraînons le modèle et nous l'utilisons pour prédire les classes des données que nous connaissons déjà :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "clf.fit(X, y)\n",
    "# y_pred : y prédite\n",
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous calculons la fraction des points correctement étiquetés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Méthode Holdout (Train/test split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour remèdier aux inconvénients de la méthode précédente, le principe de la méthode <strong>holdout</strong> consiste à supprimer une partie des données d'apprentissage et à l'utiliser pour obtenir des prédictions du modèle entraîné sur le reste des données.\n",
    "</p>\n",
    "<p>\n",
    "L'ensemble d'apprentissage (l'ensemble d'entraînement) contient une sortie connue et le modèle apprend sur ces données afin d'être généralisé à d'autres données plus tard. Nous avons besoin, aussi, de l'ensemble de données de test afin de tester la prédiction de notre modèle sur ce sous-ensemble.\n",
    "</p>\n",
    "<img src=\"images/train_test_split1.png\">\n",
    "<p>\n",
    "L'estimation de l'erreur indique ensuite comment notre modèle se comporte sur des données non vues auparavant. C'est un type simple de technique de validation croisée, également connu sous le nom de méthode <strong>train/test split</strong>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons maintenant comment faire cela en Python. Nous utilisons la bibliothèque <a href=\"http://scikit-learn.org/stable/index.html\">Scikit-Learn</a> et plus particulièrement la méthode <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">train_test_split</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importer la fonction train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Diviser les données d'entraînement en deux sous ensembles Train et Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.2, shuffle=True)\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "clf.fit(X_train, y_train)\n",
    "# evaluer le modèle sur l'ensemble de test\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Nous avons utilisé la fonction <strong>train_test_split</strong> pour faire la division (le split). Le test_size à l'intérieur de la fonction indique le pourcentage de données à conserver pour le test. C'est généralement autour de 80/20 ou 70/30.\n",
    "</p>\n",
    "<p>\n",
    "Comme on peut le voir ici, nous avons obtenu un résultat plus raisonnable.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Cross-Validation (Validation croisée)\n",
    "\n",
    "#### 3.3.1 Two-Folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'un des inconvénients de l'utilisation de la méthode holdout pour la validation de modèles est que nous avons retiré une partie de nos données de l'ensemble de données destinées à l'entraînement du modèle. Dans l'exemple du cas précédent, 20% de l'ensemble de données ne va pas contribuer à l'entraînement du modèle! Ce n'est pas optimal et peut causer des problèmes, en particulier si l'ensemble initial de données d'entraînement est petit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une façon de remèdier à ce problème est d'utiliser <strong>Cross-Validation</strong> (la validation croisée). L'idée est de construire plusieurs sous-ensemble (Folds) où chaque sous-ensemble de données est utilisé à la fois comme un ensemble d'apprentissage et comme un ensemble de validation. Visuellement, cela pourrait ressembler à la figure suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/two-folds.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous procédons à deux tests de validation, en utilisant alternativement chaque moitié des données comme dans le cas de la méthode holdout. En utilisant les données importées auparavant, nous pourrions l'implémenter comme ceci :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 1 : 0.96 Score 2 : 0.9466666666666667  Score final : 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#Importer la fonction train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Diviser les données d'entraînement en deux sous ensembles Fold1 et Fold2 ayant 50% chacun\n",
    "X1, X2, y1, y2 = train_test_split(X, y,train_size=0.5)\n",
    "# Entraîner le modèle sur le premier Fold\n",
    "clf.fit(X1, y1)\n",
    "# evaluer le modèle sur le deuxième Fold\n",
    "y_pred2 = clf.predict(X2)\n",
    "# Entraîner le modèle sur le deuxième Fold\n",
    "clf.fit(X2, y2)\n",
    "# evaluer le modèle sur le premier Fold\n",
    "y_pred1 = clf.predict(X1)\n",
    "#Afficher la précision\n",
    "score1 = accuracy_score(y1, y_pred1)\n",
    "score2 = accuracy_score(y2, y_pred2)\n",
    "score = (score1 + score2)/2\n",
    "print(\"Score 1 :\", score1, \"Score 2 :\", score2, \" Score final :\",score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons deux scores de précision, que nous pourrions combiner (par exemple, en prenant la moyenne) pour obtenir une meilleure mesure de la performance du modèle global. Cette forme particulière de validation croisée est une double validation croisée dans laquelle nous avons divisé les données en deux ensembles et utilisés chacun à son tour comme un ensemble de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 K-Folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pourrions développer l'idée précédente pour utiliser encore plus de tests, et plus de split dans les données. Par exemple, la Figure suivante est une représentation visuelle de la validation croisée contenant k folds (sous-ensembles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k-folds.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Dans l'exemple suivant, nous divisons les données en 5 groupes (folds), et nous utilisons chacun d'eux à tour de rôle pour évaluer le modèle sur l'autre 4/5 des données.\n",
    "</p>\n",
    "<p>Ce serait très fastidieux de l'implémenter manuellement. Nous pouvons utiliser la fonction <strong>cross_val_score</strong> de Scikit-Learn pour le faire succinctement :\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tous les scores : [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "Le score final : 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(\"Tous les scores :\", scores)\n",
    "print(\"Le score final :\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La répétition de la validation entre les différents sous-ensembles de données nous donne une meilleure idée de la performance de l'algorithme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Leave-One-Out-Cross-Validation (LOOCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn met en œuvre un certain nombre de schémas de validation croisée qui sont utiles dans des situations particulières. Ces schémas sont implémentés via des itérateurs dans le module model_selection. Par exemple, nous pourrions vouloir aller au cas extrême où notre nombre de splits est égal au nombre d'exemples du dataset ; c'est-à-dire que nous entraînons notre modèle sur toutes les données sauf une à chaque itération. Ce type de validation croisée peut être utilisé comme suit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tous les score : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "Score final : 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "scores = cross_val_score(clf, X, y, cv=LeaveOneOut())\n",
    "print(\"Tous les score :\",scores)\n",
    "print(\"Score final :\",scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné que nous avons 150 échantillons, la validation croisée «Leave One Out Cross Validation» donne des résultats pour 150 tets, et le score indique une prédiction réussie (1.0) ou infructueuse (0.0). La moyenne de ceux-ci nous donne une estimation du taux d'erreur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finetuning avec GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recherche par grille avec validation croisée (GridSearchCV) est une méthode d'optimisation des hyperparamètres qui explore de manière systématique un espace spécifié d'hyperparamètres, évaluant la performance d'un modèle à l'aide de la validation croisée. C'est une manière de trouver la meilleure combinaison d'hyperparamètres pour un modèle donné et un ensemble de données. Voici les étapes :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Importer les bibliothèques nécessaires :\n",
    "\n",
    "Vous commencez généralement par importer les bibliothèques nécessaires de scikit-learn :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplacez **KNeighborsClassifier** par la classe de modèle scikit-learn que vous souhaitez utiliser, telle que **SVM** pour les machines à vecteurs de support, **RandomForestClassifier** pour les forêts aléatoires, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Charger et diviser les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargez votre jeu de données\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# Divisez les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Définir le modèle et la grille de paramètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez une instance de votre modèle, KNN dans notre cas. Vous pouvez remplacer\n",
    "#KNN par n'importe quel autre calssifieur : SVM, ...\n",
    "modele = KNeighborsClassifier()\n",
    "\n",
    "# Définissez la grille de paramètres à rechercher\n",
    "param_grid = {\n",
    "    'n_neighbors': range(3,30,2),\n",
    "    #'p': [1, 2],  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "    'metric':['euclidean','manhattan','l1','l2','cosine','minkowski']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vouds pouvez ajouter d'autres paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Créer l'objet GridSearchCV :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(modele, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cv : Nombre de plis de validation croisée.\n",
    "- scoring : La métrique d'évaluation à optimiser. Les choix courants incluent 'accuracy', 'precision', 'recall', 'f1', etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Ajuster le modèle aux données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;,\n",
       "                                    &#x27;cosine&#x27;, &#x27;minkowski&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: range(3, 30, 2)},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;,\n",
       "                                    &#x27;cosine&#x27;, &#x27;minkowski&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: range(3, 30, 2)},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'metric': ['euclidean', 'manhattan', 'l1', 'l2',\n",
       "                                    'cosine', 'minkowski'],\n",
       "                         'n_neighbors': range(3, 30, 2)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Accéder aux meilleurs paramètres et au meilleur modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres :  {'metric': 'cosine', 'n_neighbors': 21}\n",
      "Meilleur score : 0.99\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs paramètres : \", grid_search.best_params_)\n",
    "print(\"Meilleur score : {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "meilleur_modele = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après l'ajustement, vous pouvez accéder aux meilleurs paramètres avec grid_search.best_params_, au meilleur score avec grid_search.best_score_, et au meilleur modèle avec grid_search.best_estimator_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Évaluer sur l'ensemble de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision sur le test : 93.33%\n"
     ]
    }
   ],
   "source": [
    "precision_test = meilleur_modele.score(X_test, y_test)\n",
    "print(\"Précision sur le test : {:.2f}%\".format(precision_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce processus vous aide à trouver la combinaison d'hyperparamètres qui donne la meilleure performance sur votre ensemble de données tout en évitant le surajustement aux données d'entraînement. Ajustez la classe du modèle, la grille des paramètres et l'ensemble de données en fonction de votre cas d'utilisation spécifique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
