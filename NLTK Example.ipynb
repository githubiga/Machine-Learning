{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fa2efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importer les modules n√©cessaires\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import stem\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b8a3526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste initiale: ['text', 'mining', ',', 'is', 'an', 'automatic', 'process', '?', 'that', 'uses', 'natural', 'language', '!', 'processing', 'to', 'extract', 'valuable', 'insights', 'from', 'unstructured', 'text', '.']\n",
      "---------------------------------------------\n",
      "Mots sans ponctuations: ['text', 'mining', 'is', 'an', 'automatic', 'process', 'that', 'uses', 'natural', 'language', 'processing', 'to', 'extract', 'valuable', 'insights', 'from', 'unstructured', 'text']\n",
      "---------------------------------------------\n",
      "Mots sans stop words: ['text', 'mining', 'automatic', 'process', 'uses', 'natural', 'language', 'processing', 'extract', 'valuable', 'insights', 'unstructured', 'text']\n",
      "---------------------------------------------\n",
      "Liste des stem: ['text', 'mine', 'automat', 'process', 'use', 'natur', 'languag', 'process', 'extract', 'valuabl', 'insight', 'unstructur', 'text']\n"
     ]
    }
   ],
   "source": [
    "phrase = \"\"\"\n",
    "Text mining, is an automatic process? that \n",
    "uses natural Language! Processing to extract \n",
    "valuable insights from unstructured text.\n",
    "\"\"\"\n",
    "#Liste de stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "phrase = phrase.lower()#Convertir la phrase en minuscule\n",
    "mots1 = word_tokenize(phrase) #Liste de tous les mots\n",
    "print(\"Liste initiale:\",mots1)\n",
    "print(\"---------------------------------------------\")\n",
    "mots2 = [] # stocker les mots sans ponctuations\n",
    "for m in mots1:\n",
    "    if m not in string.punctuation:\n",
    "        mots2.append(m)\n",
    "print(\"Mots sans ponctuations:\",mots2)\n",
    "print(\"---------------------------------------------\")\n",
    "mots3 = [] #mots sans stop words\n",
    "for m in mots2:\n",
    "    if m not in stop_words:\n",
    "        mots3.append(m)\n",
    "print(\"Mots sans stop words:\",mots3)\n",
    "print(\"---------------------------------------------\")\n",
    "mots4=[] #liste des stem (racines)\n",
    "porter = stem.porter.PorterStemmer()\n",
    "for word in mots3:\n",
    "    mots4.append(porter.stem(word))\n",
    "print(\"Liste des stem:\",mots4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9c03a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir une phrase en minuscule\n",
    "def minuscule(phrase):\n",
    "    return phrase.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38359074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization : segmentation du texte en mots\n",
    "def tokenization(phrase):\n",
    "    result = word_tokenize(phrase)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5356ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminer la ponctuations d'une phrase\n",
    "def eliminer_ponctuation(phrase):\n",
    "    result = [] # stocker les mots sans ponctuations\n",
    "    for m in tokenization(phrase):\n",
    "        if m not in string.punctuation:\n",
    "            result.append(m)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88712642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminer les stopwords\n",
    "def eliminer_stopwords(phrase):\n",
    "    result = [] #mots sans stop words\n",
    "    for m in eliminer_ponctuation(phrase):\n",
    "        if m not in stop_words:\n",
    "            result.append(m)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "587b0943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PP', 'jhgjhgjhg', 'jgjh']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminer_stopwords(\"PP, jhgjhgjhg? ; jgjh and or\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "791827ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Nettoyage du texte : \n",
    "1. convertir en minuscule\n",
    "2. Tokenization\n",
    "3. Elimination de la ponctuation\n",
    "4. Elimination des stopwords\n",
    "5. Stemming (avec Porter stemmer)\n",
    "\"\"\"\n",
    "def clean(phrase):\n",
    "    result=[] #liste des stem (racines)\n",
    "    for word in eliminer_stopwords(phrase):\n",
    "        result.append(porter.stem(word))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb86292a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PPPhhh', 'hhh', 'RR', 'ff']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenization(\"PPPhhh hhh  RR ff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd0327e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'mine',\n",
       " 'automat',\n",
       " 'process',\n",
       " 'use',\n",
       " 'natur',\n",
       " 'languag',\n",
       " 'process',\n",
       " 'extract',\n",
       " 'valuabl',\n",
       " 'insight',\n",
       " 'unstructur',\n",
       " 'text']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = \"\"\"\n",
    "Text mining, is an automatic process? that \n",
    "uses natural Language! Processing to extract \n",
    "valuable insights from unstructured text.\n",
    "\"\"\"\n",
    "clean(phrase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
